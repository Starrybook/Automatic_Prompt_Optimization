""" Globals """
TARGET_MODEL = "gpt-3.5-turbo"
OPTIMIZER_MODEL = "gpt-3.5-turbo"
TASK_CODE_NAME = 'summary-beam-0'
MOVIE_RESPONSES_DIR = "../data/response/movie" + '/' + TASK_CODE_NAME
GSM8K_RESPONSES_DIR = "../data/response/gsm8k" + '/' + TASK_CODE_NAME
DEBUG = True
CURRENT_DATASET = "gsm8k"
eval_file_path = '../data/gsm8k/eval.json'
if not os.path.exists(GSM8K_RESPONSES_DIR):
    os.makedirs(GSM8K_RESPONSES_DIR)
iter_limit = 10
B = 2
b = 2
s = 3
FEEDBACK_REASONS_NUM = 2
EVAL_SAMPLE_NUM = 50
ERROR_SAMPLE_NUM = 3
random.seed(0)

""" test """
test_file_path = '../data/gsm8k/test.json'
TEST_SAMPLE_NUM = 100
test_set = gen_samples_from_dataset(test_file_path, TEST_SAMPLE_NUM, keep_orginal_order=True)

""" template.py """
GSM8K_BEAM_INIT_PROMPTS = [ "1. Read the provided mathematical problem carefully. 2. Identify and perform the necessary calculations to solve the problem. 3. Write down the final numerical answer. 4. Provide an explanation of how you arrived at your answer.",
                            "1. Understand the mathematical question presented in the input data. 2. Execute the computations required to find the solution. 3. Document the resulting numerical value as the answer. 4. Clarify the steps taken to reach the final answer.",
                            "1. Analyze the mathematical problem given in the input. 2. Determine the appropriate mathematical operations needed to resolve the problem. 3. Capture and state the final numerical result. 4. Offer an explanation detailing the reasoning behind your solution.",
                            "1. Thoroughly examine the input mathematical problem. 2. Carry out the necessary calculations to determine the solution. 3. Express the solution as a numerical answer. 4. Explain the process and logic used to solve the problem."]

def get_initial_prompt_insts(CURRENT_DATASET, Beam_size):
    if CURRENT_DATASET == "movie":
        return [] # TODO
    elif CURRENT_DATASET == "gsm8k":
        result = []
        for prompt in GSM8K_BEAM_INIT_PROMPTS:
            result.append({"inst": prompt, "accuracy": 0.0, "responses_path": ""})
        if Beam_size > len(GSM8K_BEAM_INIT_PROMPTS):
            print("Beam size is larger than the number of initial prompts.")
            return result
        return result[:Beam_size]

# towards target model
def gen_whole_prompt_from_inst(CURRENT_DATASET, inst_from_optimizer: str, task_input: str):
    GSM8K_RESPONSES_FORMAT_SPEC = "Your answer should contain both the final answer and an explanation.\n\
Wrap your final answer with <A> and </A>.\n\
The answer between <A> and </A> tags should be only the numerical value without any additional text.\n\
Wrap your explanation with <E> and </E>."
    # \n<E>First find the number of tadpoles Trent released: 180 tadpoles * .75 = <<180*.75=135>>135 tadpoles\nThen subtract the number he let go from the total number to find the number of tadpoles he keeps: 180 tadpoles - 135 tadpoles = <<180-135=45>>45 tadpoles</E>
    GSM8K_EXAMPLE = "Input: Trent caught 180 tadpoles then let 75% of them go. How many did he keep?\nYour answer: <A>45</A>"
    if CURRENT_DATASET == "movie":
        return '' # TODO
    elif CURRENT_DATASET == "gsm8k":
        # return  inst_from_optimizer +"\n\n" \
        #         + GSM8K_RESPONSES_FORMAT_SPEC + "\n\nHere is an example of the task:\n" \
        #         + GSM8K_EXAMPLE + "\n\nNow please provide your answer to this input:\nInput:\n" \
        #         + task_input + "\nYour answer:\n"
        return  inst_from_optimizer +"\n\n" \
                + GSM8K_RESPONSES_FORMAT_SPEC + "\n\nNow please provide your answer to this input:\nInput: " \
                + task_input + "\nYour answer: "

# towards prompt optimizer model
def gen_error_examples(sample_index: int, input: str, correct_answer: str, actual_output: str):
    return f"## Wrong example {sample_index}:\n\
### Input: {input}\n\
### Correct answer and explanation: {correct_answer}\n\
### Wrong output and explanation: {actual_output}"

def gen_reflection(FEEDBACK_REASONS_NUM: int, prompt: str, error_examples: list):
    # REASONS_FORMAT_SPEC = "Please list <REASON_NUM> reasons why the prompt could have gotten these examples wrong.\nWrap each reason with <R> and </R>.\nThe reasons:"
    REASONS_FORMAT_SPEC = "Analyze at which step did the follower make mistakes in each example.\n\
Provide <REASON_NUM> suggestions in total for further breaking down the solution at the failed steps.\n\
Wrap each suggestion with <R> and </R>.\n\
The suggestions:"
    reasons_format_spec_final = REASONS_FORMAT_SPEC.replace("<REASON_NUM>", str(FEEDBACK_REASONS_NUM))
    error_examples_str = "\n\n".join(error_examples)
    return "I am attempting to write a instruction prompt to have a language model perform a task.\nMy current prompt is:\n"\
            + prompt + "\n\nBut this prompt gets the following examples wrong:\n"\
            + error_examples_str\
            + reasons_format_spec_final
        

def gen_refinement(prompt: str, error_examples: list, reasons_feedback: str):
    REFINEMENT_REQUIREMENT_SPEC = "Remember that the instruction prompt should be general and efficient, meaning that it should enable the model to produce an output close to the real result.\n\
Do not include any context-specific content shown in the reasons above. Try to make the prompt help solve more general problems.\n\
You can either modify the existing prompt or add more details to it to guide the model to the correct answer.\n\
You can also include correct examples to help the model understand the task better."
    REFINEMENT_FORMAT_SPEC = "In your response, please wrap the prompt with <P> and </P>."
    # error_examples_str = "\n\n".join(random.sample(error_examples, 2))
    error_examples_str = "\n\n".join(error_examples)
            # + prompt + "\n\nBut this prompt does not perform well and gets the some examples wrong. The possible reasons for these errors are:\n"\
    return "I am attempting to write a instruction prompt to have a language model perform a task.\nMy current prompt is:\n"\
            + prompt + "\n\nBut this prompt does not perform well and gets the some examples wrong. Here is some wrong examples: "\
            + error_examples_str + "\n\nLuckily, there have been some suggestions to eliminate the errors:\n"\
            + reasons_feedback + "\n\nBased on the above information, please write an improved prompt that could fix the problem.\n\n"\
            + REFINEMENT_REQUIREMENT_SPEC + "\n"\
            + REFINEMENT_FORMAT_SPEC + "\nThe improved prompt:\n"
