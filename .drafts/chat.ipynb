{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1000 items in the file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "def gen_eval_prompt(eval_item):\n",
    "    eval_prompt_template = f\"\"\"{eval_item[\"instruction\"]}\n",
    "{eval_item[\"input\"]}\n",
    "Your response format should be:\n",
    "Answer: <Yes or No>\n",
    "Explanation: <Your explanation here.>\n",
    "Please be concise and to the point.\n",
    "\"\"\"\n",
    "    print(\"answer to this prompt is:\", eval_item[\"output\"])\n",
    "    return eval_prompt_template\n",
    "\n",
    "\"\"\"\n",
    "json file, content like this:\n",
    "[\n",
    "    {\n",
    "        \"instruction\": \"Given the user's preference and unpreference, identify whether the user will like the target movie by answering \\\"Yes.\\\" or \\\"No.\\\".\",\n",
    "        \"input\": \"User Preference: \\\"Clockwork Orange, A (1971)\\\"\\nUser Unpreference: \\\"Mary Poppins (1964)\\\", \\\"Graduate, The (1967)\\\", \\\"Sense and Sensibility (1995)\\\", \\\"Taxi Driver (1976)\\\", \\\"Young Frankenstein (1974)\\\", \\\"Aladdin (1992)\\\", \\\"Amadeus (1984)\\\", \\\"This Is Spinal Tap (1984)\\\", \\\"When Harry Met Sally... (1989)\\\"\\nWhether the user will like the target movie \\\"Dead Poets Society (1989)\\\"?\",\n",
    "        \"output\": \"No.\"\n",
    "    },\n",
    "    ...... \n",
    "]\n",
    "Load this json file, count all the items.\n",
    "Then select 3 items randomly as evaluation set.\n",
    "\"\"\"\n",
    "random.seed(0)\n",
    "with open(\"./data/movie/eval.json\", \"r\") as f:\n",
    "    all_data = json.load(f)\n",
    "    print(f\"Total {len(all_data)} items in the file.\")\n",
    "    eval_set = random.sample(all_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Read all data in json file ./data/movie/valid.json (total 1000 items), shuffle them, and select 100 items,\n",
    "# store them in ./data/movie/eval.json\n",
    "# \"\"\"\n",
    "# random.seed(0)\n",
    "# with open(\"./data/movie/valid.json\", \"r\") as f:\n",
    "#     all_data = json.load(f)\n",
    "#     random.shuffle(all_data)\n",
    "#     eval_data = all_data[:100]\n",
    "#     with open(\"./data/movie/eval.json\", \"w\") as f:\n",
    "#         json.dump(eval_data, f, indent=4)\n",
    "\n",
    "# random.seed(0)\n",
    "# with open(\"./data/gsm8k/test.jsonl\", \"r\") as f:\n",
    "#     all_data = []\n",
    "#     for line in f:\n",
    "#         all_data.append(json.loads(line))\n",
    "#     random.shuffle(all_data)\n",
    "#     eval_data = all_data[:100]\n",
    "#     with open(\"./data/gsm8k/eval.json\", \"w\") as f:\n",
    "#         json.dump(eval_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer to this prompt is: No.\n",
      "Answer: No\n",
      "Explanation: Based on the user's preference for older movies like \"Cool Runnings\" and \"Angel and the Badman\", it is unlikely they will enjoy the more contemporary comedy of \"National Lampoon's Senior Trip\".\n",
      "==================================================\n",
      "answer to this prompt is: No.\n",
      "Answer: Yes\n",
      "Explanation: Since the user has shown a preference for action-packed movies like \"Terminator 2: Judgment Day\" and \"Transformers: The Movie, The\", they may enjoy \"Star Trek III: The Search for Spock\" which also has elements of sci-fi action.\n",
      "==================================================\n",
      "answer to this prompt is: Yes.\n",
      "Answer: No\n",
      "Explanation: \"The Secret Agent\" is a 1996 drama film, which is not in the same genre or style as the user's preferred movies such as \"Seventh Seal\" or \"Pulp Fiction\". Additionally, it does not align with the user's preference for classic or Western films like \"Good, The Bad and The Ugly\" or \"Wild Bunch\".\n",
      "==================================================\n",
      "Response saved to ./data/response/movie/res_gpt35_0515_100205.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "response format:\n",
    "[{'goden','answer','explanation'}, ...]\n",
    "\"\"\"\n",
    "gpt3_5_response = []\n",
    "def parse_response(response, eval_item):\n",
    "    answer = response.content.split(\"\\n\")[0].split(\":\")[1].strip()\n",
    "    explanation = response.content.split(\"\\n\")[1].split(\":\")[1].strip()\n",
    "    # eval_item[\"output\"] is like \"No.\"， need to remove the last char \".\"\n",
    "    return {\"golden\": eval_item[\"output\"][:-1], \"answer\": answer, \"explanation\": explanation}\n",
    "for eval_item in eval_set:\n",
    "    msgs = [{\"role\": \"user\", \"content\": gen_eval_prompt(eval_item)}]\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=msgs,\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n",
    "    print('='*50)\n",
    "    gpt3_5_response.append(parse_response(completion.choices[0].message, eval_item))\n",
    "\n",
    "# import time\n",
    "import datetime\n",
    "import os\n",
    "# 将 gpt3_5_response 写入 json 格式的文件\n",
    "response_dir = \"./data/response/movie\"\n",
    "# file name format: response_{model_name}_{timestamp}.json\n",
    "# file_name = f\"{response_dir}/res_gpt35_{int(time.time())}.json\"\n",
    "file_name = f\"{response_dir}/res_gpt35_{datetime.datetime.now().strftime('%m%d_%H%M%S')}.json\"\n",
    "# 如果文件不存在则创建文件\n",
    "if not os.path.exists(response_dir):\n",
    "    os.makedirs(response_dir)\n",
    "with open(file_name, \"w\") as f:\n",
    "    json.dump(gpt3_5_response, f, indent=4)\n",
    "    print(f\"Response saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given a file with such format:\n",
    "[{'goden','answer','explanation'}, ...]\n",
    "Calculate the accuracy of the model.\n",
    "e.g. accuracy = [correct_num where goden == answer] / total_num\n",
    "\"\"\"\n",
    "response = \"./data/response/movie/res_gpt35_0515_100205.json\"\n",
    "def rectask_evaluation(response_file):\n",
    "    with open(response_file, \"r\") as f:\n",
    "        response = json.load(f)\n",
    "        correct_num = 0\n",
    "        for item in response:\n",
    "            # goden == answer when and only when both of them contain \"Yes\" or \"No\"\n",
    "            if \"Yes\" in item[\"golden\"] and \"Yes\" in item[\"answer\"]:\n",
    "                correct_num += 1\n",
    "            elif \"No\" in item[\"golden\"] and \"No\" in item[\"answer\"]:\n",
    "                correct_num += 1\n",
    "        accuracy = correct_num / len(response)\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        return accuracy\n",
    "\n",
    "accuracy = rectask_evaluation(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "accuracy: accuracy_value\n",
    "sample_total = 5\n",
    "neg_sample = round(sample_total * (1 - accuracy_value))\n",
    "There is a response list with format:\n",
    "[{'goden','answer','explanation'}, ...]\n",
    "Select neg_sample items randomly from the response list where goden != answer\n",
    "Select sample_total - neg_sample items randomly from the response list where goden == answer\n",
    "Encapsulate the selected items into a prompt with format:\n",
    "\"I am trying to ask for LLM to finish a task with a prompt like that:\n",
    "{instruction}\n",
    "But in several cases, the model's response is not correct.\n",
    "\n",
    "case 1:\n",
    "input: {input}\n",
    "output: {output}\n",
    "model response: {answer}\n",
    "model explanation: {explanation}\n",
    "case 2: ...... (more cases)\n",
    "\n",
    "Please give 3 reasons why the model's response is not correct.\n",
    "Then give me a modified prompt which you think can help the model to improve its performance.\n",
    "Your answer should have such format:\n",
    "Reason:\n",
    "1. <reason 1>\n",
    "2. <reason 2>\n",
    "3. <reason 3>\n",
    "Modified Prompt:\n",
    "<modified prompt here>\"\n",
    "\n",
    "Then get the reason and modified prompt.\n",
    "\"\"\"\n",
    "sample_total = 5\n",
    "neg_sample = round(sample_total * (1 - accuracy))\n",
    "print(f\"neg_sample: {neg_sample} in {sample_total}\")\n",
    "# select neg_sample items where goden != answer\n",
    "neg_items = random.sample(\n",
    "    [item for item in response \n",
    "        if 'Yes' in item[\"golden\"] and 'No' in item[\"answer\"] or 'No' in item[\"golden\"] and 'Yes' in item[\"answer\"]], \n",
    "    neg_sample\n",
    ")\n",
    "# select sample_total - neg_sample items where goden == answer\n",
    "pos_items = random.sample(\n",
    "    [item for item in response \n",
    "        if 'Yes' in item[\"golden\"] and 'Yes' in item[\"answer\"] or 'No' in item[\"golden\"] and 'No' in item[\"answer\"]],\n",
    "    sample_total - neg_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pteng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
